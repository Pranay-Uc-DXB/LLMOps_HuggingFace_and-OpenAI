# LLMOps using HuggingFace and OpenAI Models


![image](https://github.com/user-attachments/assets/824670a5-62f9-42bf-b7f5-bc137112b54f)


Putting services into production is an important skill along with traditional ML, AI, & Data Science knowledge. Through this project, I want to leverage present data cloud services with evolving LLMs that will, in near future, become more cheaper, efficient, and sustainable for cloud hosting. Some of the popular use cases for LLMs in business have been listed below:

1. Chatbots and virtual assistants
2. Content writing
3. Talent acquisition and recruiting
4. Coding
5. Translation
6. Automating ad-hoc data requests or querying for analysis
7. Targeted advertising

üí° What‚Äôs the project about?

-- This project showcases a simple Q&A chatbot called the ‚ÄúWall Street Trader‚Äù hosted in Google Cloud using microservices such as Kubernetes and docker integrated with CI/CD capabilities via Github actions. 

‚ùì What's the purpose?

-- Showcase one of the several popular use cases of LLMs (Q&A Chatbots) using OpenAI and HuggingFace models and showcase my ability to put this service into production 

‚öí Tech Stack:
- FastAPI: Core of my microservice that handles API logic
- Docker: Used to containerize my FastAPI application
- Kubernetes: For automating deploying, scaling, and managing docker applications (In my case only 1 application)
- GitHub Actions: To automate testing, building, and deploying code, directly from my GitHub repository.
